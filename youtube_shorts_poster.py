#!/usr/bin/env python3
"""
Enhanced YouTube Shorts Uploader with Theme/Attire Integration
Uses AI-generated metadata from the dancer content pipeline
"""

import os
import sys
import time
import json
import pickle
import random
from pathlib import Path
from datetime import datetime

# --- Google API Libraries ---
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from googleapiclient.errors import HttpError

# === CONFIGURATION ===
CLIENT_SECRETS_FILE = "client_secret.json"
TOKEN_PICKLE_FILE = 'youtube_token.pickle'
CONTENT_PLAN_FILE = 'content_plan.json'  # Generated by metadata generator
POSTED_LOG_FILE = Path("posted_to_youtube.json")
UPLOAD_HISTORY_FILE = Path("upload_history_detailed.json")

# Directory Settings
DANCERS_CONTENT_BASE = Path(r"H:\dancers_content")
UPSCALED_SUBFOLDER = "4k_upscaled"
COMPILED_SUBFOLDER = "compiled"
REELS_SUBFOLDER = "reels"

# API and Upload Settings
SCOPES = ["https://www.googleapis.com/auth/youtube.upload"]
API_SERVICE_NAME = "youtube"
API_VERSION = "v3"
MIN_DELAY_SECONDS = 180  # 3 minutes
MAX_DELAY_SECONDS = 480  # 8 minutes
VIDEO_PRIVACY_STATUS = "public"
ENABLE_AGE_RESTRICTION = True

# Advanced Upload Settings
ENABLE_SMART_SCHEDULING = True
MAX_UPLOADS_PER_DAY = 10
OPTIMAL_UPLOAD_HOURS = [10, 14, 18, 20]
ENABLE_METADATA_ROTATION = True

def get_authenticated_service():
    """Authenticate with YouTube API."""
    creds = None
    token_pickle_path = Path(TOKEN_PICKLE_FILE)
    if token_pickle_path.exists():
        with open(token_pickle_path, 'rb') as token:
            creds = pickle.load(token)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)
            creds = flow.run_local_server(port=0)
        with open(token_pickle_path, 'wb') as token:
            pickle.dump(creds, token)
    return build(API_SERVICE_NAME, API_VERSION, credentials=creds)

def load_enhanced_content_plan():
    """Load content plan with theme/attire metadata."""
    try:
        with open(CONTENT_PLAN_FILE, 'r', encoding='utf-8') as f:
            plan = json.load(f)
            
        if "content_blocks" not in plan or not plan["content_blocks"]:
            print(f"‚ùå CRITICAL: '{CONTENT_PLAN_FILE}' missing content_blocks")
            return None, None
            
        plan_info = {
            "run_theme": plan.get("run_theme", "Unknown"),
            "run_attire": plan.get("run_attire", "Unknown"), 
            "total_variations": plan.get("total_variations", len(plan["content_blocks"])),
            "generated_timestamp": plan.get("generated_timestamp", "Unknown")
        }
        
        return plan["content_blocks"], plan_info
        
    except FileNotFoundError:
        print(f"‚ùå CRITICAL: Content plan file '{CONTENT_PLAN_FILE}' not found.")
        print("üí° TIP: Run the metadata generator first!")
        return None, None
    except json.JSONDecodeError:
        print(f"‚ùå CRITICAL: Invalid JSON in '{CONTENT_PLAN_FILE}'")
        return None, None

def get_posted_videos():
    """Get list of already posted videos."""
    if not POSTED_LOG_FILE.exists(): 
        return []
    try:
        with open(POSTED_LOG_FILE, 'r') as f: 
            return json.load(f)
    except (json.JSONDecodeError, FileNotFoundError): 
        return []

def get_upload_history():
    """Get detailed upload history."""
    if not UPLOAD_HISTORY_FILE.exists():
        return []
    try:
        with open(UPLOAD_HISTORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (json.JSONDecodeError, FileNotFoundError):
        return []

def add_to_upload_history(video_path: Path, metadata_used: dict, upload_result: dict, plan_info: dict):
    """Add detailed record to upload history."""
    history = get_upload_history()
    
    record = {
        "timestamp": datetime.now().isoformat(),
        "video_filename": video_path.name,
        "video_size_mb": round(video_path.stat().st_size / 1024 / 1024, 2),
        "upload_success": upload_result.get("success", False),
        "youtube_video_id": upload_result.get("video_id"),
        "metadata_used": {
            "title": metadata_used.get("title_template", ""),
            "description_preview": metadata_used.get("description_template", "")[:100] + "...",
            "tags_count": len(metadata_used.get("tags", [])),
            "variation_id": metadata_used.get("metadata", {}).get("variation_id")
        },
        "source_content": {
            "run_theme": plan_info.get("run_theme", "Unknown"),
            "run_attire": plan_info.get("run_attire", "Unknown"),
            "content_plan_timestamp": plan_info.get("generated_timestamp")
        },
        "upload_settings": {
            "privacy_status": VIDEO_PRIVACY_STATUS,
            "age_restriction": ENABLE_AGE_RESTRICTION
        }
    }
    
    if not upload_result.get("success"):
        record["error_details"] = upload_result.get("error", "Unknown error")
    
    history.append(record)
    
    # Keep only last 100 records
    if len(history) > 100:
        history = history[-100:]
    
    with open(UPLOAD_HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=2, ensure_ascii=False)

def add_to_posted_log(video_path: Path):
    """Add to simple posted videos list."""
    posted_list = get_posted_videos()
    posted_list.append(video_path.name)
    with open(POSTED_LOG_FILE, 'w') as f: 
        json.dump(posted_list, f, indent=4)

def find_all_unposted_videos():
    """Find all videos that haven't been uploaded yet."""
    try:
        run_folders = sorted(
            [d for d in DANCERS_CONTENT_BASE.iterdir() if d.is_dir() and d.name.startswith("Run_")],
            key=lambda x: x.stat().st_mtime, reverse=True
        )
        if not run_folders:
            print("ERROR: No 'Run_*' folders found.")
            return []
            
        reels_dir = run_folders[0] / UPSCALED_SUBFOLDER / COMPILED_SUBFOLDER / REELS_SUBFOLDER
        if not reels_dir.is_dir():
            print(f"ERROR: Reels directory not found at: {reels_dir}")
            return []
            
    except Exception as e:
        print(f"ERROR: Could not find run folder: {e}")
        return []
    
    posted_videos = get_posted_videos()
    all_reels = sorted(reels_dir.glob("*.mp4"), key=lambda p: p.stat().st_ctime)
    unposted = [p for p in all_reels if p.name not in posted_videos]
    
    print(f"üìä Video Stats:")
    print(f"   Total videos found: {len(all_reels)}")
    print(f"   Already posted: {len(posted_videos)}")
    print(f"   Ready to upload: {len(unposted)}")
    
    return unposted

def select_metadata_for_video(content_blocks: list, video_index: int, used_variations: set):
    """Smart selection of metadata variation for each video."""
    if not ENABLE_METADATA_ROTATION:
        return random.choice(content_blocks)
    
    # Try to use variations we haven't used yet
    unused_blocks = [block for block in content_blocks 
                     if block.get("metadata", {}).get("variation_id") not in used_variations]
    
    if unused_blocks:
        selected = random.choice(unused_blocks)
        used_variations.add(selected.get("metadata", {}).get("variation_id"))
        return selected
    else:
        # All variations used, reset and pick randomly
        used_variations.clear()
        return random.choice(content_blocks)

def create_upload_request_body(chosen_content: dict, video_path: Path):
    """Create upload request body with enhanced metadata."""
    
    title = chosen_content["title_template"]
    description = chosen_content["description_template"]
    tags = chosen_content["tags"]
    
    # Add video-specific info to description
    description += f"\n\nüé¨ Video: {video_path.stem}"
    description += f"\n‚è∞ Uploaded: {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    
    request_body = {
        "snippet": {
            "title": title,
            "description": description,
            "tags": tags,
            "categoryId": "17"  # Sports
        },
        "status": {
            "privacyStatus": VIDEO_PRIVACY_STATUS,
            "selfDeclaredMadeForKids": False,
            "madeForKids": False
        }
    }
    
    # Add age restriction if enabled
    if ENABLE_AGE_RESTRICTION:
        request_body["contentDetails"] = {
            "contentRating": {
                "ytRating": "ytAgeRestricted"
            }
        }
    
    return request_body

def check_daily_upload_limit():
    """Check if we've hit daily upload limit."""
    if not ENABLE_SMART_SCHEDULING:
        return True
        
    history = get_upload_history()
    today = datetime.now().date()
    
    today_uploads = [
        record for record in history 
        if datetime.fromisoformat(record["timestamp"]).date() == today
        and record["upload_success"]
    ]
    
    uploads_today = len(today_uploads)
    print(f"üìÖ Uploads today: {uploads_today}/{MAX_UPLOADS_PER_DAY}")
    
    return uploads_today < MAX_UPLOADS_PER_DAY

def calculate_smart_delay():
    """Calculate intelligent delay between uploads."""
    if not ENABLE_SMART_SCHEDULING:
        return random.randint(MIN_DELAY_SECONDS, MAX_DELAY_SECONDS)
    
    current_hour = datetime.now().hour
    
    # Shorter delays during peak hours
    if current_hour in OPTIMAL_UPLOAD_HOURS:
        return random.randint(MIN_DELAY_SECONDS, MIN_DELAY_SECONDS + 60)
    else:
        return random.randint(MIN_DELAY_SECONDS + 120, MAX_DELAY_SECONDS)

def main():
    print("=" * 80)
    print("üöÄ ENHANCED YOUTUBE SHORTS UPLOADER")
    print("   with Theme/Attire Integration")
    print("=" * 80)
    
    # Step 1: Load enhanced content plan
    print("[1] Loading AI-generated content plan...")
    content_blocks, plan_info = load_enhanced_content_plan()
    if not content_blocks:
        sys.exit(1)
    
    print(f"‚úÖ Loaded {len(content_blocks)} viral metadata variations")
    print(f"üìã Content Plan Info:")
    print(f"   üé≠ Theme: {plan_info['run_theme']}")
    print(f"   üëó Attire: {plan_info['run_attire']}")
    print(f"   üìä Variations: {plan_info['total_variations']}")
    print(f"   ‚è∞ Generated: {plan_info['generated_timestamp']}")
    
    # Display settings
    print(f"\n‚öôÔ∏è Upload Settings:")
    print(f"   üîû Age Restriction: {'Enabled (18+)' if ENABLE_AGE_RESTRICTION else 'Disabled'}")
    print(f"   üìÖ Smart Scheduling: {'Enabled' if ENABLE_SMART_SCHEDULING else 'Disabled'}")
    print(f"   üîÑ Metadata Rotation: {'Enabled' if ENABLE_METADATA_ROTATION else 'Disabled'}")
    print(f"   üéØ Privacy: {VIDEO_PRIVACY_STATUS}")

    # Step 2: Authenticate
    try:
        youtube_service = get_authenticated_service()
        print("‚úÖ YouTube authentication successful")
    except Exception as e:
        print(f"‚ùå Authentication failed: {e}")
        sys.exit(1)

    # Step 3: Find videos
    print(f"\n[3] Finding videos to upload...")
    videos_to_upload = find_all_unposted_videos()
    if not videos_to_upload:
        print("‚ú® All videos are already posted!")
        sys.exit(0)

    # Step 4: Check upload limits
    if not check_daily_upload_limit():
        print("‚ö†Ô∏è Daily upload limit reached. Try again tomorrow.")
        sys.exit(0)

    total_videos = len(videos_to_upload)
    print(f"\nüé¨ Ready to upload {total_videos} videos")
    
    # Step 5: Upload loop with enhanced tracking
    used_variations = set()
    successful_uploads = 0
    failed_uploads = 0
    
    for i, video_path in enumerate(videos_to_upload):
        print("-" * 80)
        print(f"üì§ UPLOADING VIDEO {i + 1}/{total_videos}")
        print(f"   File: {video_path.name}")
        print(f"   Size: {round(video_path.stat().st_size / 1024 / 1024, 2)} MB")
        
        # Select metadata variation
        chosen_content = select_metadata_for_video(content_blocks, i, used_variations)
        request_body = create_upload_request_body(chosen_content, video_path)
        
        print(f"  üìù Using title: {request_body['snippet']['title']}")
        print(f"  üè∑Ô∏è Tags: {len(request_body['snippet']['tags'])} tags")
        if ENABLE_AGE_RESTRICTION:
            print("  üîû Age restriction: ENABLED (18+ only)")

        upload_result = {"success": False}
        
        try:
            media = MediaFileUpload(video_path, chunksize=-1, resumable=True)
            insert_request = youtube_service.videos().insert(
                part=",".join(request_body.keys()),
                body=request_body,
                media_body=media
            )
            print("  ‚è≥ Starting upload to YouTube...")
            response = insert_request.execute()
            
            video_id = response.get('id')
            print(f"  ‚úÖ SUCCESS: Uploaded! Video ID: {video_id}")
            
            upload_result = {"success": True, "video_id": video_id}
            add_to_posted_log(video_path)
            successful_uploads += 1

        except HttpError as e:
            print(f"  ‚ùå FAILED (HTTP Error): {e}")
            upload_result = {"success": False, "error": str(e)}
            if "contentRating" in str(e):
                print("  üí° TIP: Try disabling age restriction (set ENABLE_AGE_RESTRICTION = False)")
            failed_uploads += 1
            
        except Exception as e:
            print(f"  ‚ùå FAILED (Unexpected Error): {e}")
            upload_result = {"success": False, "error": str(e)}
            failed_uploads += 1

        # Add to detailed history
        add_to_upload_history(video_path, chosen_content, upload_result, plan_info)

        # Smart delay between uploads
        if i < total_videos - 1:
            delay = calculate_smart_delay()
            print(f"  üò¥ WAITING for {delay // 60}m {delay % 60}s...")
            time.sleep(delay)

    # Final summary
    print("\n" + "=" * 80)
    print("üìä UPLOAD SUMMARY")
    print("=" * 80)
    print(f"‚úÖ Successful uploads: {successful_uploads}")
    print(f"‚ùå Failed uploads: {failed_uploads}")
    print(f"üé≠ Content theme: {plan_info['run_theme']}")
    print(f"üëó Content attire: {plan_info['run_attire']}")
    print("=" * 80)
    
    if successful_uploads > 0:
        print("üéâ UPLOADS COMPLETED!")
    else:
        print("‚ùå NO SUCCESSFUL UPLOADS")
        sys.exit(1)

if __name__ == "__main__":
    main()